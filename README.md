**🧾 🎯 Project Title: LLM Fine Tuning and Evaluation - Llama 3.2  
📅 Project Timeline: October 2024 – February 2025**  
🎥 YouTube Demo: Not available  
📦 GitHub Source Code: <https://github.com/IvanSicaja/2024.12.27_GitHub_LLM-Fine-Tuning-and-Evaluation---Llama-3.2>

\----------------------------------------------------------------------------------------------------------------

🏷️ My Personal Profiles: ⬇︎  
🎥 Video Portfolio: To be added  
📦 GitHub Profile: <https://github.com/IvanSicaja>  
🔗 LinkedIn: <https://www.linkedin.com/in/ivan-si%C4%8Daja-832682222>  
🎥 YouTube: <https://www.youtube.com/@ivan_sicaja>

\----------------------------------------------------------------------------------------------------------------

### 📚🔍 Project description: ⬇︎⬇︎⬇︎

### 💡 App Purpose

To provide a **domain-specific conversational AI** capable of answering technical queries in automation, robotics, and programming, with reliable evaluation metrics validating performance.

### 🧠 How It Works

This project involved fine-tuning the **Llama 3.2-1B-Instruct** model on a custom dataset of technical questions and answers related to ROS, PLCs, Arduino, and automation. Over four months, the project encompassed full **data preprocessing, tokenization, model training, evaluation, and deployment**. Multiple evaluation metrics, including **BLEU, ROUGE, METEOR, BERTScore, and perplexity**, were applied to ensure the model’s performance. Additionally, a **custom knowledge chatbot** was implemented to demonstrate practical inference, enabling context-aware responses to user queries.

The project combined **GPU-based fine-tuning in Google Colab A100**, model evaluation pipelines, and deployment-ready scripts for interaction with the fine-tuned model.

**Project Workflow:**

1. **Data Preprocessing:** Cleaning, tokenization, and input formatting.
2. **Model Fine-Tuning:** Training Llama-3.2-1B-Instruct on domain-specific dataset with optimizations for GPU.
3. **Evaluation:** Computing BLEU, ROUGE, METEOR, BERTScore, and perplexity across sample questions.
4. **Deployment:** Creating a chatbot interface for real-time user interaction.
5. **Feedback Loop:** Evaluating answers and adjusting training parameters for improved accuracy.

### ⚠️ Note

TBD

### 🔧 Tech Stack

**Python, PyTorch, Transformers, Hugging Face Hub, Google Colab, spaCy, NLTK, Pandas, BLEU, ROUGE, METEOR, BERTScore, Llama 3.2-1B, Custom Dataset, Tokenization, Model Fine-Tuning, GPU Acceleration, Evaluation Pipelines, Chatbot Development**

---

### 📸 Project Snapshot

TBD.

---

### 🎥 Video Demonstration

TBD.

---


### 📣 Hashtags Section

**\# #LLM #AI #MachineLearning #DeepLearning #PyTorch #HuggingFace #Transformers #GoogleColab #GPU #FineTuning #Chatbot #NLP #EvaluationMetrics #BLEU #ROUGE #METEOR #BERTScore #DataPreprocessing #Tokenization #ModelTraining #ModelDeployment #DomainSpecificAI #Automation #Robotics #PLC #Arduino**
